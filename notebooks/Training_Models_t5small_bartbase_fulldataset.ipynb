{"cells":[{"cell_type":"markdown","metadata":{"id":"XB2eXVm4BO0D"},"source":["***IMPORT LIBRARIES***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lteZfNCPv0_G"},"outputs":[],"source":["# ////GENERALS////\n","import re\n","import json\n","import pandas as pd\n","import numpy as np\n","from typing_extensions import Type\n","import matplotlib.pyplot as plt\n","import warnings\n","\n","# ////AUTOMATIC LEARNING////\n","import tensorflow as tf\n","from datasets import load_dataset,DatasetDict,Dataset\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# ////TRANSFORMERS BY Hugging Face////\n","import transformers\n","from transformers import AutoTokenizer\n","from transformers import TFAutoModelForSeq2SeqLM\n","from transformers import DataCollatorForSeq2Seq\n","from transformers import create_optimizer, AdamWeightDecay\n","\n","# ////NLP MEASURES////\n","import nltk\n","from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import accuracy_score\n","import evaluate\n","meteor_measure = evaluate.load('meteor')\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"NU0z-ufUBO0H"},"source":["***READ THE DATASET***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpGt10ZqBO0I"},"outputs":[],"source":["#Reading the dataset JSON file\n","with open('PATH TO DATASET') as f:\n","   dataset = json.load(f)\n","\n","rows = dataset['pairs']\n","\n","# Reading Natural language (nl) and Controlled Natural lagauge (cnl)\n","nl = [row['NL'] for row in rows]\n","cnl = [row['CNL'] for row in rows]"]},{"cell_type":"markdown","metadata":{"id":"_tahiQhvnDuC"},"source":["***DATASET STRUCTURE***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IE-GDrRTi0Bj"},"outputs":[],"source":["#To Dataset Structure with train test split ratio of 85:15\n","train_dict = Dataset.from_dict({\"sentences\": nl,\"targets\": cnl})\n","train_dict = train_dict.train_test_split(test_size=0.15)\n","train_dict['train'][0]"]},{"cell_type":"markdown","metadata":{"id":"dqn_ARMnSZcA"},"source":["***TRAINING TRANSFORMERS***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V8xwSzO8D6Uk"},"outputs":[],"source":["#Using AutoTokenizer from trasnformer\n","tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzA91ds4EFX1"},"outputs":[],"source":["#Defined Prefix and model inputs\n","prefix = \"translate English to CNL: \"\n","def preprocess(data):\n","  inputs = [prefix + example for example in data[\"sentences\"]]\n","  targets = data[\"targets\"]\n","  model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n","  return model_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eUaFlSzZEKEp"},"outputs":[],"source":["# Mapped the model inputs\n","tokenized_cnl = train_dict.map(preprocess, batched=True)\n","tokenized_cnl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeQJSVxzEM9J"},"outputs":[],"source":["#Importing models 't5-small' or 'facebook/bart-base'\n","model = TFAutoModelForSeq2SeqLM.from_pretrained(\"t5-small\") # update model name 'facebook/bart-base' or give path of saved model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBxxI6hjEex_"},"outputs":[],"source":["#Used DataCollator For Seq2Seq\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors=\"tf\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2t5Gf6yDEl2r"},"outputs":[],"source":["## Dataset spliting for training on full dataset (No test set as we are training on full dataset)\n","tf_train_set = model.prepare_tf_dataset(\n","    tokenized_cnl[\"train\"],\n","    shuffle=True,\n","    batch_size=16,\n","    collate_fn=data_collator,\n",")\n","\n","tf_test_set = model.prepare_tf_dataset(\n","    tokenized_cnl[\"test\"],\n","    shuffle=False,\n","    batch_size=16,\n","    collate_fn=data_collator,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JGCyYsxsErz0"},"outputs":[],"source":["#Defined Adam optimizer with learning and weight decay rates\n","optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9in5F25tExlb"},"outputs":[],"source":["#Model compilation\n","model.compile(optimizer=optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5uKaeQrBO0K"},"outputs":[],"source":["# Define the CSVLogger callback\n","csv_logger = tf.keras.callbacks.CSVLogger('training-t5Small_FullDataset.log', separator=\",\", append=True)\n","\n","# Define the EarlyStopping callback\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dmum2oF0BO0K"},"outputs":[],"source":["# Model training\n","model.fit(tf_train_set, validation_data=tf_test_set, epochs=200)\n","history = model.fit(tf_train_set, validation_data=tf_test_set, epochs=200, callbacks=[csv_logger, es])\n","model.save_pretrained('content/t5mall_Complete_Dataset/') #save the model in specified path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QwxkPzSHBO0L"},"outputs":[],"source":["# Load the log file using pandas\n","log_data = pd.read_csv('training-t5Small_FullDataset.log')\n","\n","# Plotting training loss vs validation loss\n","plt.figure(figsize=(10, 6))\n","plt.plot(log_data['loss'], label='Training Loss')\n","plt.plot(log_data['val_loss'], label='Validation Loss')\n","plt.title('Training Loss vs Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lcVSxccDBO0L"},"outputs":[],"source":["#load the trained model\n","model = TFAutoModelForSeq2SeqLM.from_pretrained('content/t5mall_Complete_Dataset/')\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"vVueIjGJBO0L"},"source":["***BLEU SCORE FUNCTION***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-KA0bdE7BO0L"},"outputs":[],"source":["# Function to compute the BLEU Score\n","def bleu_score(model, tokenizer, test_dict):\n","    # Get the bleu score of a model\n","    #sents = test_dict['sentences'][0:5] #specify the number of sentences in case to for test run\n","    sents = test_dict['sentences'] #complete sentences\n","    predicted = predict_cnl(model, tokenizer, sents)\n","    targets = test_dict['targets']\n","    references, hypothesis = [], []\n","    for i, pred in enumerate(predicted):\n","        references.append([targets[i].split()])\n","        hypothesis.append(pred.split())\n","\n","    bleu_dic = {}\n","    print(hypothesis)\n","    bleu_dic['1-grams'] = corpus_bleu(references, hypothesis, weights=(1.0, 0, 0, 0))\n","    bleu_dic['1-2-grams'] = corpus_bleu(references, hypothesis, weights=(0.5, 0.5, 0, 0))\n","    bleu_dic['1-3-grams'] = corpus_bleu(references, hypothesis, weights=(0.3, 0.3, 0.3, 0))\n","    bleu_dic['1-4-grams'] = corpus_bleu(references, hypothesis, weights=(0.25, 0.25, 0.25, 0.25))\n","\n","    return bleu_dic\n","\n","# Compute the BLEU Score\n","bleu_train = bleu_score(model, tokenizer, train_dict)\n","bleu_train"]},{"cell_type":"markdown","metadata":{"id":"Dhvf06EEBO0L"},"source":["***METEOR SCORE FUNCTION***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-RjEgGmBO0L"},"outputs":[],"source":["# Function to compute the METEOR Score\n","def compute_meteor(model, test_dict, alpha=0.9, beta=3, gamma=0.5):\n","    sents = test_dict['sentences']\n","\n","    predicted = predict_cnl(model, tokenizer, sents)\n","    targets = test_dict['targets']\n","    references, hypothesis = [], []\n","    for i, pred in enumerate(predicted):\n","        references.append([targets[i]])\n","        hypothesis.append(pred)\n","\n","    meteor_dic = {}\n","    meteor_dic = meteor_measure.compute(predictions= hypothesis, references= references)\n","\n","    return meteor_dic\n","\n","#Compute the METEOR Score\n","meteor_train = compute_meteor(model, train_dict)\n","meteor_train\n"]},{"cell_type":"markdown","metadata":{"id":"ky87vxl8BO0L"},"source":["***INFERENCE MULTI SENTENCES***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5jXnKHiBO0L"},"outputs":[],"source":["#Sentence Cleaning function\n","def clean_sentence(sentence):\n","  regExp = '(<\\/s>|<s>|<pad>|<unk>)'\n","  return re.sub(regExp, \"\", sentence).strip()\n","\n","##Evaluate Sentence Cleaning function\n","clean_sentence('</s><s>Waiter W is working when waiter W serves a drink.</s><pad><pad><pad><pad><pad><pad><pad><pad>')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5uV9RqyxBO0L"},"outputs":[],"source":["#Predicting the CNL function\n","%%time\n","def predict_cnl(model, tokenizer, sentences):\n","  task_prefix = \"translate English to CNL: \"\n","  prefixeds = [task_prefix + sentence for sentence in sentences]\n","  predict_input = tokenizer(prefixeds, return_tensors=\"tf\", padding=True)\n","  output_sequences = model.generate(\n","    input_ids=predict_input[\"input_ids\"],\n","    attention_mask=predict_input[\"attention_mask\"],\n","    do_sample=False,  # disable sampling to test if batching affects output\n","    max_length=300, min_length=5,num_beams=1\n","  )\n","\n","  cnls = [tokenizer.decode(encoded) for encoded in output_sequences]\n","  cnls = [clean_sentence(sentence) for sentence in cnls]\n","  return cnls\n","\n","##Evaluate predict_cnl function\n","toTranslate = [\"The pub 1 is close to the pub number 2 and the pub number X, where X is equal to 3, 4.\"]\n","translateds = predict_cnl(model, tokenizer, toTranslate)"]},{"cell_type":"markdown","metadata":{"id":"J_Z8AXCaBO0L"},"source":["***PREDICTION ON TEST DATASET***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dBbfkSynBO0L"},"outputs":[],"source":["# Read the dataset\n","test_data = pd.read_excel('test.xlsx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tvJ-4jbLBO0M"},"outputs":[],"source":["# Get the sentences to predict\n","sentences_to_predict = test_data['Test Natural Language'].tolist()\n","\n","# Use your model to predict the CNL\n","predicted_cnl = predict_cnl(model, tokenizer, sentences_to_predict)\n","\n","# Now you have the predicted CNL, you need to compare with the actual CNL\n","actual_cnl = test_data['CNL'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FLb7NLqBO0M"},"outputs":[],"source":["# Create a DataFrame to store the actual and predicted CNLs\n","results_df = pd.DataFrame({'Actual CNL': actual_cnl, 'Predicted CNL': predicted_cnl})\n","\n","# Save the DataFrame to a CSV file\n","results_df.to_csv('cnl_predictions_t5Small_Complete.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NSsKh1uQBO0M"},"outputs":[],"source":["def sentence_to_words(sentence):\n","    return sentence.split(' ')\n","\n","def sentences_to_word_lists(sentences):\n","    return [sentence_to_words(sentence) for sentence in sentences]\n","\n","\n","def calculate_metrics_word_level(actual, predicted):\n","    mlb = MultiLabelBinarizer()\n","\n","    actual_words = sentences_to_word_lists(actual)\n","    predicted_words = sentences_to_word_lists(predicted)\n","\n","    # Fit the MultiLabelBinarizer on the union of actual and predicted words\n","    all_words = list(set().union(*actual_words, *predicted_words))\n","    mlb.fit([all_words])\n","\n","    actual_binary = mlb.transform(actual_words)\n","    predicted_binary = mlb.transform(predicted_words)\n","\n","    accuracy = accuracy_score(actual_binary, predicted_binary)\n","    precision = precision_score(actual_binary, predicted_binary, average='micro', zero_division=0)\n","    recall = recall_score(actual_binary, predicted_binary, average='micro', zero_division=0)\n","    f1 = f1_score(actual_binary, predicted_binary, average='micro', zero_division=0)\n","\n","    return accuracy, precision, recall, f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xY2XNE3cBO0M"},"outputs":[],"source":["print(\"Number of actual CNL sentences: \", len(actual_cnl))\n","print(\"Number of predicted CNL sentences: \", len(predicted_cnl))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BHJtYR-bBO0M"},"outputs":[],"source":["accuracy, precision, recall, f1 = calculate_metrics_word_level(actual_cnl, predicted_cnl)\n","print('Accuracy word_level:', accuracy)\n","print('Precision word_level:', precision)\n","print('Recall word_level:', recall)\n","print('F1 score word_level:', f1)"]},{"cell_type":"code","source":["# To Calculate the BLEU & MERTEOR, Load the Test Dataset from the provided Excel file\n","test_data = pd.read_excel('test.xlsx')\n","test_nl = test_data['Test Natural Language'].tolist()\n","test_cnl = test_data['CNL'].tolist()\n","test_dict = Dataset.from_dict({\"sentences\": test_nl, \"targets\": test_cnl})\n","\n","# Compute BLEU Score\n","bleu_results = bleu_score(model, tokenizer, test_dict)\n","print(\"BLEU Scores:\", bleu_results)\n","\n","# Compute METEOR Score\n","meteor_results = compute_meteor(model, test_dict)\n","print(\"METEOR Score:\", meteor_results)\n"],"metadata":{"id":"7XEGgiyn1Z-Y"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}