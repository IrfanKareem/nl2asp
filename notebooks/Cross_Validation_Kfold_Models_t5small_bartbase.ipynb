{"cells":[{"cell_type":"markdown","metadata":{"id":"0biFuGhIKPJ6"},"source":[" ***IMPORT LIBRARIES***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R11R0oGtDLUg"},"outputs":[],"source":["# ////GENERALS////\n","import os\n","import re\n","import gc\n","import time\n","import json\n","import requests\n","import numpy as np\n","import pandas as pd\n","\n","# ////AUTOMATIC LEARNING////\n","import tensorflow as tf\n","from datasets import load_dataset,DatasetDict,Dataset\n","import keras\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint\n","from typing_extensions import Type\n","\n","# ////TRANSFORMERS BY Hugging Face////\n","import transformers\n","from transformers import AutoTokenizer\n","from transformers import TFAutoModelForSeq2SeqLM\n","from transformers import DataCollatorForSeq2Seq\n","from transformers import create_optimizer, AdamWeightDecay\n","\n","# ////NLP MEASURES////\n","import nltk\n","from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n","from nltk.translate.bleu_score import corpus_bleu\n","from nltk.translate.meteor_score import meteor_score\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import accuracy_score\n","import evaluate\n","meteor_measure = evaluate.load('meteor')\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"WNkMwEGuKPKB"},"source":["***READ THE DATASET***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lteZfNCPv0_G"},"outputs":[],"source":["#Reading the dataset JSON file\n","with open('PATH TO DATASET') as f:\n","   dataset = json.load(f)\n","\n","rows = dataset['pairs']\n","\n","# Reading Natural language (nl) and Controlled Natural lagauge (cnl)\n","nl = [row['NL'] for row in rows]\n","cnl = [row['CNL'] for row in rows]"]},{"cell_type":"markdown","metadata":{"id":"_tahiQhvnDuC"},"source":["**DATASET STRUCTURE**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IE-GDrRTi0Bj"},"outputs":[],"source":["#To dataset structure\n","train_dict = Dataset.from_dict({\"sentences\": nl,\"targets\": cnl})\n","train_dict"]},{"cell_type":"markdown","metadata":{"id":"dqn_ARMnSZcA"},"source":["***TRAINING TRANSFORMERS***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V8xwSzO8D6Uk"},"outputs":[],"source":["#Using AutoTokenizer from trasnformer 't5-small' or 'facebook/bart-base'\n","tokenizer = AutoTokenizer.from_pretrained(\"t5-small\") # or update mode 'facebook/bart-base'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzA91ds4EFX1"},"outputs":[],"source":["#Defining Prefix and model inputs\n","prefix = \"translate English to CNL: \"\n","def preprocess(data):\n","  inputs = [prefix + example for example in data[\"sentences\"]]\n","  targets = data[\"targets\"]\n","  model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n","  return model_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeQJSVxzEM9J"},"outputs":[],"source":["#Importing models 't5-small' or 'facebook/bart-base'\n","model = TFAutoModelForSeq2SeqLM.from_pretrained(\"t5-small\") # update model name 'facebook/bart-base' or give path of saved model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBxxI6hjEex_"},"outputs":[],"source":["#Used DataCollator For Seq2Seq\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors=\"tf\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JGCyYsxsErz0"},"outputs":[],"source":["#Defined Adam optimizer with learning and weight decay rates\n","optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8_jGGacJ0QM_"},"outputs":[],"source":["#Dataset spliting, preprocessing, preparation and model creation\n","def split_dataset(dataset, train_idxs, test_idxs):\n","  training_dict = Dataset.from_dict({\"sentences\":dataset[train_idxs][\"sentences\"], \"targets\": dataset[train_idxs][\"targets\"]})\n","  test_dict =Dataset.from_dict({\"sentences\":dataset[test_idxs][\"sentences\"], \"targets\": dataset[test_idxs][\"targets\"]})\n","  return (training_dict, test_dict)\n","\n","def preprocessing_sentences(dataset):\n","  data = dataset.map(preprocess, batched=True)\n","  return data\n","\n","def prepare_tf_dataset(dataset):\n","  tf_dataset = model.prepare_tf_dataset(\n","      dataset,\n","      shuffle=True,\n","      batch_size=16,\n","      collate_fn=data_collator,\n","  )\n","  return tf_dataset\n","\n","def create_and_compile_model(learning_rate=2e-5, weight_decay_rate=0.01):\n","  optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n","  model = TFAutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n","  model.compile(optimizer=optimizer,metrics=['accuracy'])\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"k8Dpc_UEFCS9"},"source":["**BLUE SCORE FUNCTION**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8MEes54Bz75"},"outputs":[],"source":["%%time\n","# Function to compute the BLEU Score\n","def bleu_score(model, tokenizer, test_dict):\n","    sents = test_dict['sentences']\n","    predicted = predict_cnl(model, tokenizer, sents)\n","    targets = test_dict['targets']\n","    references, hypothesis = [], []\n","    for i, pred in enumerate(predicted):\n","        references.append([targets[i].split()])\n","        hypothesis.append(pred.split())\n","\n","    bleu_dic = {}\n","    print(hypothesis)\n","    bleu_dic['1-grams'] = corpus_bleu(references, hypothesis, weights=(1.0, 0, 0, 0))\n","    bleu_dic['1-2-grams'] = corpus_bleu(references, hypothesis, weights=(0.5, 0.5, 0, 0))\n","    bleu_dic['1-3-grams'] = corpus_bleu(references, hypothesis, weights=(0.3, 0.3, 0.3, 0))\n","    bleu_dic['1-4-grams'] = corpus_bleu(references, hypothesis, weights=(0.25, 0.25, 0.25, 0.25))\n","\n","    return bleu_dic"]},{"cell_type":"markdown","metadata":{"id":"y48cS-SiEwHH"},"source":["***METEOR SCORE FUNCTION***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJ0HOZfkDy9I"},"outputs":[],"source":["# Function to compute the METEOR Score\n","%%time\n","def compute_meteor(model, test_dict, alpha=0.9, beta=3, gamma=0.5):\n","    sents = test_dict['sentences']\n","\n","    predicted = predict_cnl(model, tokenizer, sents)\n","    targets = test_dict['targets']\n","    references, hypothesis = [], []\n","    for i, pred in enumerate(predicted):\n","        references.append([targets[i]])\n","        hypothesis.append(pred)\n","\n","    meteor_dic = {}\n","    meteor_dic = meteor_measure.compute(predictions= hypothesis, references= references)\n","\n","    return meteor_dic"]},{"cell_type":"markdown","metadata":{"id":"2Blh_7OfKPKE"},"source":["***SYNTAX_CHECK FUNCTION***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xi2NE_rYKPKE"},"outputs":[],"source":["# ////We used a self created REST API that interact with the syntax checker implemented in the CNL2ASP tool (https://github.com/dodaro/cnl2asp)\n","BASE_URL = \"http://XYZ/api/check_syntax\"  #Your check syntax API link replace'XYZ'\n","\n","def call_check_syntax_api(sentence, verbose = 1):\n","  body = {'cnls': sentence}\n","  headers = {\"X-API-KEY\": \"YOUR API KEY REPLACE HERE\"}  #Update your API key\n","  try:\n","    resp = requests.post(BASE_URL, json = body, headers = headers)\n","    if(resp.status_code != 200):\n","      if(verbose == 1):\n","        print(sentence)\n","        print(resp.json())\n","        print('-----------------')\n","      return None\n","    return resp.json()\n","  except:\n","    return None\n","\n","def evaluate_syntax(sentences, verbose = 1):\n","  if(sentences is None or len(sentences) == 0):\n","      raise Exception(\"Sentences list is empty\")\n","\n","  errorCount = 0\n","  problematic_sentences = []\n","  for sentence in sentences:\n","    resp = call_check_syntax_api(sentence)\n","    if(resp is None or \"cli_message\" not in resp or resp[\"cli_message\"] != \"Input file fits the grammar.\"):\n","      errorCount += 1\n","      problematic_sentences.append(sentence)\n","    time.sleep(0.1)\n","  summary = {\n","      'errorCount': errorCount,\n","      'total': len(sentences),\n","      'avg': errorCount/len(sentences),\n","      'problematics': problematic_sentences\n","  }\n","  return summary\n","\n","##Evaluate the syntax Sample CNLs\n","evaluate_syntax([\"A node goes from 1 to 50.\", \"A node goes om 1 to 50.\"])"]},{"cell_type":"markdown","metadata":{"id":"oK2D-mhomexG"},"source":["**INFERENCE MULTI SENTENCES**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xa1ofKMJNrVk"},"outputs":[],"source":["#Sentence Cleaning function\n","def clean_sentence(sentence):\n","  regExp = '(<\\/s>|<s>|<pad>|<unk>)'\n","  return re.sub(regExp, \"\", sentence).strip()\n","\n","##Evaluate Sentence Cleaning function\n","clean_sentence('</s><s>Waiter W is working when waiter W serves a drink.</s><pad><pad><pad><pad><pad><pad><pad><pad>')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J69DP5jaDnU4"},"outputs":[],"source":["#Predicting the CNL function\n","def predict_cnl(model, tokenizer, sentences):\n","  task_prefix = \"translate English to CNL: \"\n","  prefixeds = [task_prefix + sentence for sentence in sentences]\n","  predict_input = tokenizer(prefixeds, return_tensors=\"tf\", padding=True)\n","  output_sequences = model.generate(\n","    input_ids=predict_input[\"input_ids\"],\n","    attention_mask=predict_input[\"attention_mask\"],\n","    do_sample=False,  # disable sampling to test if batching affects output\n","    max_length=300, min_length=5,num_beams=1\n","  )\n","  cnls = [tokenizer.decode(encoded) for encoded in output_sequences]\n","  cnls = [clean_sentence(sentence) for sentence in cnls]\n","  return cnls\n","\n","##Evaluate predict_cnl function\n","toTranslate = [\"The pub 1 is close to the pub number 2 and the pub number X, where X is equal to 3, 4.\"]\n","translateds = predict_cnl(model, tokenizer, toTranslate)\n","print(translateds)"]},{"cell_type":"markdown","metadata":{"id":"XUBlySgqnv6V"},"source":["***INFERENCE***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eTGSXBMrE3hm"},"outputs":[],"source":["def predict_predicates(sentence):\n","  task_prefix = \"translate English to CNL: \"\n","  predict_input = tokenizer([task_prefix + sentence], return_tensors=\"tf\", padding=True)\n","\n","  output_sequences = model.generate(\n","    input_ids=predict_input[\"input_ids\"],\n","    attention_mask=predict_input[\"attention_mask\"],\n","    do_sample=False,  # disable sampling to test if batching affects output\n","    max_length=300, min_length=20,num_beams=1\n","  )\n","\n","  return tokenizer.decode(output_sequences[0])\n","\n","print(predict_predicates('Serving as many drinks as possible is preferred with low priority.'))"]},{"cell_type":"markdown","metadata":{"id":"5_5_qdNhnBsE"},"source":["**TRAINING CROSS VALIDATION K=5**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6KguFPmsswv","scrolled":false},"outputs":[],"source":["%%time\n","## K-fold Cross-Validation##\n","def get_model_name(k):\n","    return 'model_'+str(k)+'.h5py'\n","\n","LOSS = []\n","VALIDAITON_LOSS = []\n","\n","# Define an empty list to store the test_idxs for each split\n","all_test_idxs = []\n","\n","save_dir = 'content/Kfold5_t5small/' #Give your saving path here\n","\n","# prepare cross validation\n","kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n","\n","# Create a DataFrame to store the scores\n","score_df = pd.DataFrame(columns=['split', 'bleu_1gram', 'bleu_2gram', 'bleu_3gram', 'bleu_4gram', 'meteor', 'train_time', 'score_time'])\n","\n","start_time = time.time()\n","# enumerate splits\n","for index, (train_idxs, test_idxs) in enumerate(kfold.split(train_dict)):\n","  # Save the test_idxs in a file\n","  print(\"///Save the test_idxs in a file///\")\n","  np.savetxt(save_dir + 'test_idxs_' + str(index) + '.txt', test_idxs, fmt='%d')\n","  # Append the test_idxs to the list\n","  all_test_idxs.append(test_idxs)\n","  # Append the test_idxs to the list\n","  all_test_idxs.append(test_idxs)\n","  # Save all_test_idxs as a numpy array\n","  np.save(save_dir + 'all_test_idxs.npy', all_test_idxs)\n","\n","  # ///GETTING SPLITS///\n","  print(\"///GETTING SPLITS///\")\n","  (training_dict, test_dict) = split_dataset(train_dict, train_idxs, test_idxs)\n","\n","  # ///TOKENIZING///\n","  print(\"///TOKENIZING///\")\n","  training_dict = preprocessing_sentences(training_dict)#training_dict.map(preprocess, batched=True)\n","  test_dict = preprocessing_sentences(test_dict)#test_dict.map(preprocess, batched=True)\n","\n","  # ///COLLATOR///\n","  print(\"///COLLATOR///\")\n","  tf_train_set = prepare_tf_dataset(training_dict)\n","  tf_test_set = prepare_tf_dataset(test_dict)\n","\n","  # ///MODEL///\n","  print(\"///create_and_compile_model///\")\n","  tf.keras.backend.clear_session()\n","  model = create_and_compile_model()\n","\n","  # ///TRAIN///\n","  print('///TRAIN/// SPLIT: %s' % (index))\n","  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n","  csv_logger = tf.keras.callbacks.CSVLogger('trainingt5small.log', separator=\",\", append=True)\n","\n","\t# CREATE CALLBACKS\n","  checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(index), save_best_only=True, monitor='val_loss', verbose=1, mode='min', save_weights_only=False)\n","  split_start_time = time.time()\n","  history = model.fit(tf_train_set, validation_data=tf_test_set, epochs=1, callbacks=[es,checkpoint, csv_logger])\n","  split_train_time = time.time() - split_start_time\n","\n","  best_model = create_and_compile_model()\n","  best_model.load_weights(save_dir+get_model_name(index))\n","  gc.collect()\n","\n","  start_score_time = time.time()\n","  bleu = bleu_score(best_model, tokenizer, test_dict)\n","  meteor = compute_meteor(best_model, test_dict)\n","  score_time = time.time() - start_score_time\n","  score_df.loc[len(score_df)] = [index, bleu['1-grams'], bleu['1-2-grams'], bleu['1-3-grams'], bleu['1-4-grams'], meteor, split_train_time, score_time]\n","\n","  print(history.history)\n","\n","# Save the scores DataFrame to a CSV file\n","score_df.to_csv(save_dir + 'scores.csv', index=False)\n","\n","print(\"k-fold Cross-Validation Training execution time: \", time.time() - start_time)"]},{"cell_type":"markdown","metadata":{"id":"v53AGvk2KPKF"},"source":["***PLOTTING THE LOG FILES***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o90LtJAUVcu8"},"outputs":[],"source":["# Load the log file using pandas\n","log_data = pd.read_csv('trainingT5Small.log')\n","\n","# Plotting training loss vs validation loss\n","plt.figure(figsize=(10, 6))\n","plt.plot(log_data['loss'], label='Training Loss')\n","plt.plot(log_data['val_loss'], label='Validation Loss')\n","plt.title('Training Loss vs Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Yn6GID9DnMWb"},"source":["***TESTING AFTER TRAINING***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5qSQWlxnKtj"},"outputs":[],"source":["%%time\n","def predict_cnl(model, tokenizer, sentences):\n","  task_prefix = \"translate English to CNL: \"\n","  prefixeds = [task_prefix + sentence for sentence in sentences]\n","  #predict_input = tokenizer([task_prefix + sentence], return_tensors=\"tf\", padding=True)\n","  predict_input = tokenizer(prefixeds, return_tensors=\"tf\", padding=True)\n","  # print(predict_input)\n","  output_sequences = model.generate(\n","    input_ids=predict_input[\"input_ids\"],\n","    attention_mask=predict_input[\"attention_mask\"],\n","    do_sample=False,  # disable sampling to test if batching affects output\n","    max_length=300, min_length=5,num_beams=1\n","  )\n","  # print(output_sequences)\n","  cnls = [tokenizer.decode(encoded) for encoded in output_sequences]\n","  cnls = [clean_sentence(sentence) for sentence in cnls]\n","  return cnls\n","\n","# toTranslate = train_dict['sentences'][:1120]\n","toTranslate = [\"If the value of C1 is lower than C2, C1 will take on the same color as C2, Likewise, whenever C2 is given a color, C1 will be assigned the same color.\"]\n","translateds = predict_cnl(model, tokenizer, toTranslate)\n","print(translateds)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_p9KFlGHKPKG"},"source":["***CALCULATING SYNTAX CHECK BY SPLIT***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vADBI9QsKPKG"},"outputs":[],"source":["#Calculating the syntax check of each split\n","save_dir = 'content/Kfold5_t5small/'\n","# Load the test indices from the text file\n","test_idxs = np.loadtxt(save_dir + 'test_idxs.txt', dtype=int) #Update text ids .txt files\n","\n","# Get the corresponding test data using the test_idxs\n","test_dict = Dataset.from_dict({\"sentences\": [train_dict['sentences'][i] for i in test_idxs],\n","                               \"targets\": [train_dict['targets'][i] for i in test_idxs]})\n","\n","# Predict CNLs using the loaded model\n","predicted_cnls = predict_cnl(model, tokenizer, test_dict['sentences'])\n","\n","# Apply the syntax check function on the predicted CNLs\n","summary = evaluate_syntax(predicted_cnls)\n","\n","# Convert the summary to a DataFrame\n","df = pd.DataFrame(summary)\n","\n","# Save the DataFrame to a CSV file\n","df.to_csv('T5_syntax_check_results.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"UNqh1GcMKPKK"},"source":["***EVALUATING MODEL ON TEST DATASET***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wxlHHhDZKPKK"},"outputs":[],"source":["# Read the dataset\n","test_data = pd.read_excel('test.xlsx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qg154ZqTKPKK"},"outputs":[],"source":["# Get the sentences to predict\n","sentences_to_predict = test_data['Test Natural Language'].tolist()\n","\n","# Use your model to predict the CNL\n","predicted_cnl = predict_cnl(model, tokenizer, sentences_to_predict)\n","\n","# Now you have the predicted CNL, you need to compare with the actual CNL\n","actual_cnl = test_data['CNL'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bRuO-ef5KPKK"},"outputs":[],"source":["# Create a DataFrame to store the actual and predicted CNLs\n","results_df = pd.DataFrame({'Actual CNL': actual_cnl, 'Predicted CNL': predicted_cnl})\n","\n","# Save the DataFrame to a CSV file\n","results_df.to_csv('cnl_predictions_t5Small5fold.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9BdbvNmKPKK"},"outputs":[],"source":["def sentence_to_words(sentence):\n","    return sentence.split(' ')\n","\n","def sentences_to_word_lists(sentences):\n","    return [sentence_to_words(sentence) for sentence in sentences]\n","\n","    #Defined metrices to calaculate the accuracy, precision, recall, f1 scores\n","def calculate_metrics_word_level(actual, predicted):\n","    mlb = MultiLabelBinarizer()\n","\n","    actual_words = sentences_to_word_lists(actual)\n","    predicted_words = sentences_to_word_lists(predicted)\n","\n","    # Fit the MultiLabelBinarizer on the union of actual and predicted words\n","    all_words = list(set().union(*actual_words, *predicted_words))\n","    mlb.fit([all_words])\n","\n","    actual_binary = mlb.transform(actual_words)\n","    predicted_binary = mlb.transform(predicted_words)\n","\n","    accuracy = accuracy_score(actual_binary, predicted_binary)\n","    precision = precision_score(actual_binary, predicted_binary, average='micro', zero_division=0)\n","    recall = recall_score(actual_binary, predicted_binary, average='micro', zero_division=0)\n","    f1 = f1_score(actual_binary, predicted_binary, average='micro', zero_division=0)\n","\n","    return accuracy, precision, recall, f1\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsEr4IH6KPKK"},"outputs":[],"source":["print(\"Number of actual CNL sentences: \", len(actual_cnl))\n","print(\"Number of predicted CNL sentences: \", len(predicted_cnl))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wdBWE0x_KPKK"},"outputs":[],"source":["accuracy, precision, recall, f1 = calculate_metrics_word_level(actual_cnl, predicted_cnl)\n","print('Accuracy word_level:', accuracy)\n","print('Precision word_level:', precision)\n","print('Recall word_level:', recall)\n","print('F1 score word_level:', f1)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}